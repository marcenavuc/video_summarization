{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c8e20f",
   "metadata": {},
   "source": [
    "## Как сопоставить время/индекс\n",
    "\n",
    "Нужно как-то резать промпты, чтобы в контекст влезало\n",
    "\n",
    "Нужно что-то почитать для промт инжиниринга\n",
    "\n",
    "\n",
    "В крайний случай нужно будет брать эмбединги из whisper и vit и учить свою модельку на них\n",
    "\n",
    "C GPT есть проблемы с воспроизведением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1a196204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import whisper\n",
    "from PIL import Image\n",
    "from moviepy.editor import VideoFileClip\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_APIKEY\")\n",
    "\n",
    "vit_model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "vit_feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "vit_tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "asr_model = whisper.load_model(\"tiny.en\")\n",
    "\n",
    "\n",
    "FPS = 1 \n",
    "IMAGE_SIZE = (224, 224)\n",
    "video_path = \"/media/mark/ADATA HV620S/diplom/tvsum/ydata-tvsum50-v1_1/video/Bhxk-O1Y7Ho.mp4\"\n",
    "\n",
    "labels_df = pd.read_parquet('labels.parquet')\n",
    "labels_df = labels_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "\n",
    "def save_audio(filepath):\n",
    "    filename = os.path.basename(filepath).split(\".\")[0]\n",
    "    result_path = filename + \".mp3\"\n",
    "    VideoFileClip(filepath).audio.write_audiofile(result_path)\n",
    "    return result_path\n",
    "    \n",
    "\n",
    "def get_images(video_path, fps, image_size):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    images = []\n",
    "\n",
    "    for i in range(0, frame_count, int(cap.get(cv2.CAP_PROP_FPS) / fps)):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).resize(image_size)\n",
    "            images.append(image)\n",
    "\n",
    "    cap.release()\n",
    "    return images\n",
    "\n",
    "\n",
    "\n",
    "def get_image_caption(images, feature_extractor, tokenizer, model, **kwags):\n",
    "    pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n",
    "    output_ids = model.generate(pixel_values, **kwags)\n",
    "\n",
    "    preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    \n",
    "    df = pd.DataFrame({\"text\": [pred.strip() for pred in preds]})\n",
    "    df = df.reset_index().rename(columns={\"index\": \"second\"})\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_text_recognition(asr_model, audio_file):\n",
    "    asr_result = asr_model.transcribe(audio_file)\n",
    "    return pd.DataFrame([\n",
    "        {\n",
    "            'start_second': segment['start'],\n",
    "            'end_second': segment['end'],\n",
    "            'text': segment['text'],\n",
    "        }\n",
    "        for segment in asr_result['segments']\n",
    "    ])\n",
    "\n",
    "\n",
    "def create_prompt(asr_result, ic_result):\n",
    "    return \"\"\"\n",
    "        Summarize the video by description data\n",
    "        Decription of each image per second:\n",
    "        {ic_result}\n",
    "\n",
    "        Speech recognition results:\n",
    "        {asr_result}\n",
    "        Return summarization as table with columns of second and importance. importance should be from 0 to 1\n",
    "        \"\"\".format(ic_result=ic_result.to_string(index=None),\n",
    "                   asr_result=asr_result.to_string(index=None)\n",
    "                  )\n",
    "\n",
    "\n",
    "def transform_predictions(pred_text):\n",
    "    result = []\n",
    "    for line in pred_text.split('\\n'):\n",
    "        pnumbers = line.strip().split() \n",
    "        if len(pnumbers) != 2:\n",
    "            continue\n",
    "        try:\n",
    "            result.append({'second': float(pnumbers[0]), 'prob': float(pnumbers[1])})\n",
    "        except:\n",
    "            continue\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "\n",
    "def fill_preds(ic_result, preds):\n",
    "    sec = np.array(range(ic_result['second'].max() + 1))\n",
    "    prob = np.zeros(shape=sec.shape)\n",
    "    \n",
    "    \n",
    "    for i in range(preds.shape[0]-1):\n",
    "        prob[(sec >= preds.iloc[i].second) & (sec <= preds.iloc[i+1].second)] = preds.iloc[i].prob\n",
    "    last_i = preds.shape[0]-1\n",
    "    prob[sec >= preds.iloc[last_i].second] = preds.iloc[last_i].prob  \n",
    "    return pd.DataFrame({'second': sec, 'prob': prob})\n",
    "\n",
    "\n",
    "def eval_metric(preds, annotation, t=0.5):\n",
    "    post_preds = preds.copy()\n",
    "    post_preds['reps'] = annotation.shape[0] // preds['second'].max()\n",
    "    post_preds = post_preds.loc[post_preds.index.repeat(post_preds.reps)]\n",
    "    post_preds = post_preds['prob'].values\n",
    "    \n",
    "    same_len = min(post_preds.shape[0], annotation.shape[0])\n",
    "    y_true = np.where(annotation[:same_len] >= t, 1, 0)\n",
    "    y_pred = np.where(post_preds[:same_len] >= t, 1, 0)\n",
    "    return f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d50c22b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in 0tmA_C6XwfM.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "\n",
      "        second       importance\n",
      "        0            0.8\n",
      "        12.96        0.7\n",
      "        18.76        0.6\n",
      "        23.96        0.5\n",
      "        29.88        0.6\n",
      "        34.64        0.5\n",
      "        37.64        0.5\n",
      "        42.36        0.4\n",
      "        46.08        0.4\n",
      "        51.40        0.4\n",
      "        54.92        0.3\n",
      "        56.68        0.3\n",
      "        60.56        0.3\n",
      "        65.00        0.4\n",
      "        74.40        0.4\n",
      "        79.44        0.3\n",
      "        81.24        0.3\n",
      "        87.80        0.4\n",
      "        91.44        0.4\n",
      "        97.44        0.3\n",
      "        102.44       0.3\n",
      "        107.48       0.3\n",
      "        111.24       0.3\n",
      "        115.80       0.2\n",
      "        117.44       0.2\n",
      "        122.68       0.3\n",
      "        127.32       0.3\n",
      "        129.00       0.3\n",
      "\n",
      "Sample of preds      second  prob\n",
      "0         0   0.8\n",
      "1         1   0.8\n",
      "2         2   0.8\n",
      "3         3   0.8\n",
      "4         4   0.8\n",
      "..      ...   ...\n",
      "137     137   0.3\n",
      "138     138   0.3\n",
      "139     139   0.3\n",
      "140     140   0.3\n",
      "141     141   0.3\n",
      "\n",
      "[142 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05194805194805195"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = \"/media/mark/ADATA HV620S/diplom/tvsum/ydata-tvsum50-v1_1/video/0tmA_C6XwfM.mp4\"\n",
    "ic_kwargs = {\"max_length\": 10, \"num_beams\": 2}\n",
    "\n",
    "\n",
    "audio_path = save_audio(video_path)\n",
    "images = get_images(video_path, FPS, IMAGE_SIZE)\n",
    "ic_result = get_image_caption(images, vit_feature_extractor, vit_tokenizer, vit_model, **ic_kwargs)\n",
    "\n",
    "asr_result = get_text_recognition(asr_model, '0tmA_C6XwfM.mp3')\n",
    "prompt = create_prompt(asr_result, ic_result)\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=prompt,\n",
    "  temperature=0.7,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['text'])\n",
    "tdf = transform_predictions(response['choices'][0]['text'])\n",
    "preds = fill_preds(ic_result, tdf)\n",
    "\n",
    "print(\"Sample of preds\", preds)\n",
    "filename = os.path.basename(video_path).split(\".\")[0]\n",
    "annotation = labels_df[labels_df['video_id'] == filename].annotation.values[0]\n",
    "\n",
    "eval_metric(preds, annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6097834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
